{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sec_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/equeumco/sec_test/blob/master/sec_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxREunso0REA",
        "colab_type": "code",
        "outputId": "d30ec498-0e79-441f-ce42-ca4956aa4567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "user = getpass('GitHub user')\n",
        "password = getpass('GitHub password')\n",
        "os.environ['GITHUB_AUTH'] = user + ':' + password\n",
        "\n",
        "#set up the project for us, unzip an archive \n",
        "!rm -r 'sec_test'\n",
        "!rm -r 'Archives'\n",
        "!git clone https://$GITHUB_AUTH@github.com/equeumco/sec_test.git\n",
        "!cp \"sec_test/test_ticker_list.csv\" \"test_ticker_list.csv\" #move ticker list to root\n",
        "!cp \"sec_test/Archives.zip\" \"Archives.zip\" #move ticker list to root\n",
        "!cp \"sec_test/sec_R_utils.R\" \"sec_R_utils.R\" #move ticker list to root\n",
        "!cp \"sec_test/sec_py_utils.py\" \"sec_py_utils.py\" #move ticker list to root\n",
        "!unzip -q Archives.zip\n",
        "\n",
        "####\n",
        "#edit the file ticker_list_csv for your own ticker set\n",
        "####"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GitHub user··········\n",
            "GitHub password··········\n",
            "rm: cannot remove 'sec_test': No such file or directory\n",
            "rm: cannot remove 'Archives': No such file or directory\n",
            "Cloning into 'sec_test'...\n",
            "remote: Enumerating objects: 77, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 77 (delta 47), reused 3 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (77/77), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04jdag6BhSmY",
        "colab_type": "code",
        "outputId": "b355f8af-eb44-4d8a-ad99-2e75cc86d50a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# activate R magic\n",
        "# why use R here?  \n",
        "# edgarWebR pulls sections really well\n",
        "\n",
        "import rpy2\n",
        "%load_ext rpy2.ipython"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/rpy2/robjects/pandas2ri.py:14: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
            "  from pandas.core.index import Index as PandasIndex\n",
            "/usr/local/lib/python3.6/dist-packages/rpy2/robjects/pandas2ri.py:34: UserWarning: pandas >= 1.0 is not supported.\n",
            "  warnings.warn('pandas >= 1.0 is not supported.')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSYJWc0DyRFR",
        "colab_type": "code",
        "outputId": "d42f51e8-1f30-49d9-b784-453c52bb2416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "%%R\n",
        "#installs take a bit of time the first time...\n",
        "print('Startup: install packages... (may take a few minutes the first time)')\n",
        "library(devtools)\n",
        "devtools::install_github(\"mwaldstein/edgarWebR\",quiet = TRUE) \n",
        "print('Done with edgarWebR install')\n",
        "devtools::install_github(\"r-lib/xml2\",quiet = TRUE) #the CRAN xml breaks edgarWebR\n",
        "print('Done with xml2 install')\n",
        "#devtools::install_github(\"DavisVaughan/furrr\")\n",
        "install.packages('furrr',quiet = TRUE) #fine to use CRAN\n",
        "print('Done with furr install')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1] \"Startup: install packages... (may take a few minutes the first time)\"\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "R[write to console]: Loading required package: usethis\n",
            "\n",
            "R[write to console]: Installing 1 packages: curl\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2x4-h6m0x-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%R\n",
        "\n",
        "#this run also can take a bit of time...\n",
        "source('sec_R_utils.R')\n",
        "\n",
        "#library from https://mwaldstein.github.io/edgarWebR/\n",
        "suppressPackageStartupMessages(library(edgarWebR)) #this is an up to date library with an active maintainer.\n",
        "suppressPackageStartupMessages(library(xml2))\n",
        "suppressPackageStartupMessages(library(knitr))\n",
        "suppressPackageStartupMessages(library(dplyr))\n",
        "suppressPackageStartupMessages(library(purrr))\n",
        "suppressPackageStartupMessages(library(rvest))\n",
        "suppressPackageStartupMessages(library(tidyr))\n",
        "suppressPackageStartupMessages(library(readr))\n",
        "\n",
        "#https://github.com/DavisVaughan/furrr\n",
        "library(furrr) \n",
        "\n",
        "#read our ticker list\n",
        "df_tickers <- read_csv('test_ticker_list.csv',col_types = cols()) \n",
        "\n",
        "#create our data folder\n",
        "dir.create('sec_data_folder', showWarnings = FALSE)\n",
        "\n",
        "#prep for multiprocessing\n",
        "future::plan(multiprocess)\n",
        "\n",
        "#tell us what we're doing\n",
        "print(paste0('Running for ',nrow(df_tickers),' tickers.'))\n",
        "\n",
        "#map get_document_text from sec_R_utils.R across the vector Symbol in the df_tickers dataframe\n",
        "#show progress bar, thank you Davis \n",
        "df_data <- future_map_dfr(df_tickers$Symbol, get_document_text,.progress = TRUE) #takes a few minutes\n",
        "\n",
        "print('done')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UYcX52F7_pu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#move from R to python\n",
        "\n",
        "!pip install pandarallel\n",
        "from sec_py_utils import *\n",
        "\n",
        "import numpy as np\n",
        "from pandarallel import pandarallel\n",
        "import pandas as pd\n",
        "\n",
        "pandarallel.initialize()\n",
        "\n",
        "df_tickers = pd.read_csv('test_ticker_list.csv')\n",
        "\n",
        "master_list_df = []\n",
        "list_tickers = df_tickers['Symbol']\n",
        "\n",
        "for ticker in list_tickers:\n",
        "    py_write_log(\"working on...\"+ticker)\n",
        "    tic = time.perf_counter()\n",
        "\n",
        "    if path.exists(\"sec_data_folder/\"+ticker+\".csv\"):\n",
        "\n",
        "        df_text = pd.read_csv(\"sec_data_folder/\"+ticker+\".csv\")\n",
        "        if len(df_text) > 0:\n",
        "\n",
        "            df_text['ticker'] = ticker\n",
        "\n",
        "            df_discussion = df_text[df_text['section']=='discussion']\n",
        "\n",
        "            df_out = df_discussion.parallel_apply(func_sentiment, axis=1)\n",
        "            df_out.columns = ['ticker','section','type','period_date','neu','neg','pos','compound','keywords_found','text','num_rows']\n",
        "            \n",
        "            if len(df_out) > 0:\n",
        "\n",
        "                df_out = df_out.groupby(['ticker','period_date','type']).sum().reset_index()\n",
        "                df_out['neg'] = df_out['neg']/df_out['num_rows']\n",
        "                df_out['neu'] = df_out['neu']/df_out['num_rows']\n",
        "                df_out['pos'] = df_out['pos']/df_out['num_rows']\n",
        "                df_out['compound'] = df_out['compound']/df_out['num_rows']\n",
        "\n",
        "                df_error = df_out[df_out['compound'] == 0]\n",
        "                if not df_error.empty:\n",
        "                    py_write_log(\"zero values...\"+ticker)\n",
        "                    df_error.to_csv('sec_nlp_errors.csv',mode = 'a')\n",
        "\n",
        "                df_out.drop(['keywords_found'],axis = 1)\n",
        "                df_out['compound_baseline'] = df_out['compound'] / df_out['compound'].mean()\n",
        "                df_out['neg_baseline'] = df_out['neg'] / df_out['neg'].mean()\n",
        "                df_out['pos_baseline'] = df_out['pos'] / df_out['pos'].mean()\n",
        "                df_out['compound_bdiff'] = df_out['compound_baseline'].diff()\n",
        "                df_out['neg_bdiff'] = df_out['neg_baseline'].diff()\n",
        "                df_out['pos_bdiff'] = df_out['pos_baseline'].diff()\n",
        "                df_out['compound_zscore'] = (df_out['compound'] - df_out['compound'].mean())/df_out['compound'].std(ddof=0)\n",
        "\n",
        "                #to iterate is human, to cache is divine\n",
        "                str_score_file = \"sec_data_folder/\"+ticker+\"_score.csv\"\n",
        "                df_out.to_csv(str_score_file)\n",
        "\n",
        "                master_list_df.append(df_out)\n",
        "            else:\n",
        "                py_write_log(\"missing...\"+ticker)\n",
        "        else:\n",
        "            py_write_log(ticker+\" has no data.\")\n",
        "    toc = time.perf_counter()\n",
        "    py_write_log(f\"Text processed in {toc - tic:0.4f} seconds\")\n",
        "\n",
        "if master_list_df:\n",
        "    df_data = pd.concat(master_list_df)\n",
        "    df_data.to_csv('df_data.csv')\n",
        "\n",
        "df = df_data[['period_date','ticker','compound_baseline']]\n",
        "df['quarter_end'] = pd.to_datetime(df['period_date'])\n",
        "df['quarter_end'] = df.quarter_end.map(lambda x: x.strftime('%Y-%m-%d'))\n",
        "\n",
        "#modify odd quarter ends\n",
        "df.loc[df.quarter_end == '2017-04-01', 'quarter_end'] = '2017-03-31'\n",
        "df.loc[df.quarter_end == '2017-07-01', 'quarter_end'] = '2017-06-30'\n",
        "df.loc[df.quarter_end == '2018-04-01', 'quarter_end'] = '2018-03-31'\n",
        "df.loc[df.quarter_end == '2018-07-01', 'quarter_end'] = '2018-06-30'\n",
        "\n",
        "df['quarter_end'] = pd.to_datetime(df['quarter_end'])\n",
        "df['quarter_end'] = df['quarter_end'].dt.to_period('q').dt.end_time #floor at end of quarter\n",
        "df['quarter_end'] = df.quarter_end.map(lambda x: x.strftime('%Y-%m-%d')) #format\n",
        "\n",
        "import numpy as np\n",
        "df_data_pivot = pd.pivot_table(df, values='compound_baseline', index=['quarter_end'],\n",
        "                columns=['ticker'], aggfunc=np.sum, fill_value=0).reset_index()\n",
        "\n",
        "df_data_pivot.to_csv(\"df_data_pivot.csv\")\n",
        "\n",
        "print('done!')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuyztVzxz7uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#########\n",
        "#uncomment these lines to post df_data_pivot.csv to a google sheet\n",
        "#########\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials as GC\n",
        "gc = gspread.authorize(GC.get_application_default())\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "title = 'sec_nlp_data'\n",
        "gc.create(title)  # if not exist\n",
        "sheet = gc.open(title).sheet1\n",
        "set_with_dataframe(sheet, df_data_pivot) \n",
        "print('done!')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcrhRus4oJJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#a sample chart of one ticker.\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "df_plot = df_data[df_data['ticker'] == 'XOM'] #setting w copy warning\n",
        "\n",
        "df_plot['period_date'] = pd.to_datetime(df_plot['period_date'])\n",
        "df_plot['period_date'] = df_plot.period_date.map(lambda x: x.strftime('%Y-%m-%d')) #format\n",
        "\n",
        "df_plot.compound = pd.to_numeric(df_plot.compound)\n",
        "\n",
        "df_plot.plot.bar(x='period_date', y='compound', rot=90,title='XOM')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0MHyEDT9t7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#zip your archives for local use... you can download into your git directory.\n",
        "#the R code will not pull if it finds these files.\n",
        "!zip -r Archives.zip Archives"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}