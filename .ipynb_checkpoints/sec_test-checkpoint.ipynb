{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/equeumco/sec_test/blob/master/sec_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "MxREunso0REA",
    "outputId": "5a85e39a-35b7-41d4-c410-3b3960559c01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'sec_test': No such file or directory\n",
      "rm: cannot remove 'Archives': No such file or directory\n",
      "Cloning into 'sec_test'...\n",
      "fatal: could not read Username for 'https://github.com': No such device or address\n",
      "cp: cannot stat 'sec_test/test_ticker_list.csv': No such file or directory\n",
      "cp: cannot stat 'sec_test/Archives.zip': No such file or directory\n",
      "cp: cannot stat 'sec_test/sec_R_utils.R': No such file or directory\n",
      "cp: cannot stat 'sec_test/sec_py_utils.py': No such file or directory\n",
      "unzip:  cannot find or open Archives.zip, Archives.zip.zip or Archives.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#set up the project for us, unzip an archive \n",
    "!rm -r 'sec_test'\n",
    "!rm -r 'Archives'\n",
    "!git clone https://github.com/equeumco/sec_test.git #errors if exists but doesn't halt exe\n",
    "!cp \"sec_test/test_ticker_list.csv\" \"test_ticker_list.csv\" #move ticker list to root\n",
    "!cp \"sec_test/Archives.zip\" \"Archives.zip\" #move ticker list to root\n",
    "!cp \"sec_test/sec_R_utils.R\" \"sec_R_utils.R\" #move ticker list to root\n",
    "!cp \"sec_test/sec_py_utils.py\" \"sec_py_utils.py\" #move ticker list to root\n",
    "!unzip -q Archives.zip\n",
    "\n",
    "####\n",
    "#edit the file ticker_list_csv for your own ticker set\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "04jdag6BhSmY",
    "outputId": "a6693fec-3296-4df4-b633-37f825169ef6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/rpy2/robjects/pandas2ri.py:14: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import Index as PandasIndex\n",
      "/usr/local/lib/python3.6/dist-packages/rpy2/robjects/pandas2ri.py:34: UserWarning: pandas >= 1.0 is not supported.\n",
      "  warnings.warn('pandas >= 1.0 is not supported.')\n"
     ]
    }
   ],
   "source": [
    "# activate R magic\n",
    "# why use R here?  \n",
    "# edgarWebR pulls sections really well\n",
    "\n",
    "import rpy2\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "OSYJWc0DyRFR",
    "outputId": "5dd5df2e-861e-4522-8265-006bd90b81bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Startup: install packages... (may take a few minutes the first time)\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: usethis\n",
      "\n",
      "R[write to console]: Installing 1 packages: curl\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Done with edgarWebR install\"\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "#installs take a bit of time the first time...\n",
    "print('Startup: install packages... (may take a few minutes the first time)')\n",
    "library(devtools)\n",
    "devtools::install_github(\"mwaldstein/edgarWebR\",quiet = TRUE) \n",
    "print('Done with edgarWebR install')\n",
    "devtools::install_github(\"r-lib/xml2\",quiet = TRUE) #the CRAN xml breaks edgarWebR\n",
    "print('Done with xml2 install')\n",
    "#devtools::install_github(\"DavisVaughan/furrr\")\n",
    "install.packages('furrr',quiet = TRUE) #fine to use CRAN\n",
    "print('Done with furr install')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D2x4-h6m0x-V"
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "#this run also can take a bit of time...\n",
    "source('sec_R_utils.R')\n",
    "\n",
    "#library from https://mwaldstein.github.io/edgarWebR/\n",
    "suppressPackageStartupMessages(library(edgarWebR)) #this is an up to date library with an active maintainer.\n",
    "suppressPackageStartupMessages(library(xml2))\n",
    "suppressPackageStartupMessages(library(knitr))\n",
    "suppressPackageStartupMessages(library(dplyr))\n",
    "suppressPackageStartupMessages(library(purrr))\n",
    "suppressPackageStartupMessages(library(rvest))\n",
    "suppressPackageStartupMessages(library(tidyr))\n",
    "suppressPackageStartupMessages(library(readr))\n",
    "\n",
    "#https://github.com/DavisVaughan/furrr\n",
    "library(furrr) \n",
    "\n",
    "#read our ticker list\n",
    "df_tickers <- read_csv('test_ticker_list.csv',col_types = cols()) \n",
    "\n",
    "#create our data folder\n",
    "dir.create('sec_data_folder', showWarnings = FALSE)\n",
    "\n",
    "#prep for multiprocessing\n",
    "future::plan(multiprocess)\n",
    "\n",
    "#tell us what we're doing\n",
    "print(paste0('Running for ',nrow(df_tickers),' tickers.'))\n",
    "\n",
    "#map get_document_text from sec_R_utils.R across the vector Symbol in the df_tickers dataframe\n",
    "#show progress bar, thank you Davis \n",
    "df_data <- future_map_dfr(df_tickers$Symbol, get_document_text,.progress = TRUE) #takes a few minutes\n",
    "\n",
    "print('done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1UYcX52F7_pu"
   },
   "outputs": [],
   "source": [
    "#move from R to python\n",
    "\n",
    "!pip install pandarallel\n",
    "from sec_py_utils import *\n",
    "\n",
    "import numpy as np\n",
    "from pandarallel import pandarallel\n",
    "import pandas as pd\n",
    "\n",
    "pandarallel.initialize()\n",
    "\n",
    "df_tickers = pd.read_csv('test_ticker_list.csv')\n",
    "\n",
    "master_list_df = []\n",
    "list_tickers = df_tickers['Symbol']\n",
    "\n",
    "for ticker in list_tickers:\n",
    "    py_write_log(\"working on...\"+ticker)\n",
    "    tic = time.perf_counter()\n",
    "\n",
    "    if path.exists(\"sec_data_folder/\"+ticker+\".csv\"):\n",
    "\n",
    "        df_text = pd.read_csv(\"sec_data_folder/\"+ticker+\".csv\")\n",
    "        if len(df_text) > 0:\n",
    "\n",
    "            df_text['ticker'] = ticker\n",
    "\n",
    "            df_discussion = df_text[df_text['section']=='discussion']\n",
    "\n",
    "            df_out = df_discussion.parallel_apply(func_sentiment, axis=1)\n",
    "            df_out.columns = ['ticker','section','type','period_date','neu','neg','pos','compound','keywords_found','text','num_rows']\n",
    "            \n",
    "            if len(df_out) > 0:\n",
    "\n",
    "                df_out = df_out.groupby(['ticker','period_date','type']).sum().reset_index()\n",
    "                df_out['neg'] = df_out['neg']/df_out['num_rows']\n",
    "                df_out['neu'] = df_out['neu']/df_out['num_rows']\n",
    "                df_out['pos'] = df_out['pos']/df_out['num_rows']\n",
    "                df_out['compound'] = df_out['compound']/df_out['num_rows']\n",
    "\n",
    "                df_error = df_out[df_out['compound'] == 0]\n",
    "                if not df_error.empty:\n",
    "                    py_write_log(\"zero values...\"+ticker)\n",
    "                    df_error.to_csv('sec_nlp_errors.csv',mode = 'a')\n",
    "\n",
    "                df_out.drop(['keywords_found'],axis = 1)\n",
    "                df_out['compound_baseline'] = df_out['compound'] / df_out['compound'].mean()\n",
    "                df_out['neg_baseline'] = df_out['neg'] / df_out['neg'].mean()\n",
    "                df_out['pos_baseline'] = df_out['pos'] / df_out['pos'].mean()\n",
    "                df_out['compound_bdiff'] = df_out['compound_baseline'].diff()\n",
    "                df_out['neg_bdiff'] = df_out['neg_baseline'].diff()\n",
    "                df_out['pos_bdiff'] = df_out['pos_baseline'].diff()\n",
    "                df_out['compound_zscore'] = (df_out['compound'] - df_out['compound'].mean())/df_out['compound'].std(ddof=0)\n",
    "\n",
    "                #to iterate is human, to cache is divine\n",
    "                str_score_file = \"sec_data_folder/\"+ticker+\"_score.csv\"\n",
    "                df_out.to_csv(str_score_file)\n",
    "\n",
    "                master_list_df.append(df_out)\n",
    "            else:\n",
    "                py_write_log(\"missing...\"+ticker)\n",
    "        else:\n",
    "            py_write_log(ticker+\" has no data.\")\n",
    "    toc = time.perf_counter()\n",
    "    py_write_log(f\"Text processed in {toc - tic:0.4f} seconds\")\n",
    "\n",
    "if master_list_df:\n",
    "    df_data = pd.concat(master_list_df)\n",
    "    df_data.to_csv('df_data.csv')\n",
    "\n",
    "df = df_data[['period_date','ticker','compound_baseline']]\n",
    "df['quarter_end'] = pd.to_datetime(df['period_date'])\n",
    "df['quarter_end'] = df.quarter_end.map(lambda x: x.strftime('%Y-%m-%d'))\n",
    "\n",
    "#modify odd quarter ends\n",
    "df.loc[df.quarter_end == '2017-04-01', 'quarter_end'] = '2017-03-31'\n",
    "df.loc[df.quarter_end == '2017-07-01', 'quarter_end'] = '2017-06-30'\n",
    "df.loc[df.quarter_end == '2018-04-01', 'quarter_end'] = '2018-03-31'\n",
    "df.loc[df.quarter_end == '2018-07-01', 'quarter_end'] = '2018-06-30'\n",
    "\n",
    "df['quarter_end'] = pd.to_datetime(df['quarter_end'])\n",
    "df['quarter_end'] = df['quarter_end'].dt.to_period('q').dt.end_time #floor at end of quarter\n",
    "df['quarter_end'] = df.quarter_end.map(lambda x: x.strftime('%Y-%m-%d')) #format\n",
    "\n",
    "import numpy as np\n",
    "df_data_pivot = pd.pivot_table(df, values='compound_baseline', index=['quarter_end'],\n",
    "                columns=['ticker'], aggfunc=np.sum, fill_value=0).reset_index()\n",
    "\n",
    "df_data_pivot.to_csv(\"df_data_pivot.csv\")\n",
    "\n",
    "print('done!')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iuyztVzxz7uo"
   },
   "outputs": [],
   "source": [
    "#########\n",
    "#uncomment these lines to post df_data_pivot.csv to a google sheet\n",
    "#########\n",
    "\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "import gspread\n",
    "from oauth2client.client import GoogleCredentials as GC\n",
    "gc = gspread.authorize(GC.get_application_default())\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "title = 'sec_nlp_data'\n",
    "gc.create(title)  # if not exist\n",
    "sheet = gc.open(title).sheet1\n",
    "set_with_dataframe(sheet, df_data_pivot) \n",
    "print('done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EcrhRus4oJJp"
   },
   "outputs": [],
   "source": [
    "#a sample chart of one ticker.\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "df_plot = df_data[df_data['ticker'] == 'XOM'] #setting w copy warning\n",
    "\n",
    "df_plot['period_date'] = pd.to_datetime(df_plot['period_date'])\n",
    "df_plot['period_date'] = df_plot.period_date.map(lambda x: x.strftime('%Y-%m-%d')) #format\n",
    "\n",
    "df_plot.compound = pd.to_numeric(df_plot.compound)\n",
    "\n",
    "df_plot.plot.bar(x='period_date', y='compound', rot=90,title='XOM')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b0MHyEDT9t7c"
   },
   "outputs": [],
   "source": [
    "#zip your archives for local use... you can download into your git directory.\n",
    "#the R code will not pull if it finds these files.\n",
    "!zip -r Archives.zip Archives"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "sec_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
